---
title: "Understanding the impact of electronically-delivered parenting advice"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large\bf Hanwen Vivian~Zhang} (\texttt{vivian3@stanford.edu}) \\
    {\large\bf George~Kachergis} (\texttt{george.kachergis@gmail.com}) \\
    {\large\bf Michael C.~Frank} (\texttt{mcfrank@stanford.edu}) \\ 
    Department of Psychology, Stanford University \\ 
    Palo Alto, CA 94301 USA}

abstract: >
    Early parenting practices play an important role in shaping the future 
    outcomes of young children [@Hart1995; @Heckman2006]. 
    In particular, high quality early interactions and early language input appear to 
    facilitate more effective language learning and higher levels of school performance. 
    The rise in electronic parenting applications ("apps") holds the promise of delivering 
    low-cost, positive interventions on parenting style to a variety of different populations. 
    Of special interest are the parents of very young children, who are often difficult to reach in other ways. 
    Yet little is known about the effects of communicating to parents through app-based interventions.
    MTLD, types and tokens, joint attention, proportion of nouns/verbs/adjectives, 
    affect, concreteness, mean length of utterance...
    
keywords: >
    digital parenting advice; joint attention; lexical diversity; guided play; 
    
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r libraries, echo=F, include=F}
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(psych)
library(langcog)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)
source("multiplot.R")

select <- dplyr::select # masked by MASS
theme_set(theme_few())
```

# Introduction

Children spend a large portion of their waking time at play in their environment.
Playing with objects may allow them to discover hidden features, as well as to build a causal understanding of how the objects interact. 
Beyond learning object features, the laws of physics, and causal relationships [e.g., @Schulz2007], during play children practice motor skills that help them effectively navigate their world [@Singer2006].
Social play can help children learn about human relationships, both through imitation of adult behaviors and by experiencing and learning to process emotional events [@Singer2006].

## Guided Play Scaffolds Learning
Children's early play behaviors are often assisted by more skilled and knowledgeable play partners such as their caregivers and older siblings (Kaye, 1970). 
Under such expert guidance, children are encouraged and motivated to engage in more advanced play, undertaking explorations that push the boundaries of what they would be able to do unaided (Vygotsky, 197X).
These tutorial interactions have been shown to be a "a crucial feature of infancy and childhood" (Wood, 1970).
Thus, with the knowledge of both play and tutorial interactions, guided play, "where children actively engage in pleasurable and seemingly spontaneous activities under the direction of adults" (Hirsh-Pasek, 2008), 
have drawn researchers' interest. 
Weisberg showed that, with preschoolers, guided play scaffolds the environment while still allowing children to maintain a large degree of control, 
and it outperforms direct-instruction approaches in encouraging a variety of positive academic outcomes (Weisberg, Hirsh-Pasek and Golinkoff, 2013).
Massey specifically showed that guided play could facilitate children's vocabulary and comprehensive language development and subsequent literacy skills (Massey, 2013).

## Improving Parenting Practices and Language Use
(early interventions on parenting practices can help children's outcomes)
Thus, including guided play in parenting practices early on is important and should help with children's later performances. Suskind did a parent-directed home-visiting intervention experiment in 2015, 
and found that parents in experimental group have greater knowledge of language development and this effect sustained after the experiment is done. 
However, more interactive outcomes, like parent word type and token numbers, child word types, conversational turn counts and child vocalization counts, 
increased during the home-visiting but did not sustain after four months of intervention (there are more detailed sustainibility differences of these measure. should I make it more clear?) [@Suskind2015].
The fact that changes did not sustain could be due to the intervention itself, 
or could merely be that home-visiting is not sustainable enough for parents to easily and constantly get parenting advice.

## Effectiveness of Digital Delivery
(apps are an easy way to deliver curated, age-appropriate parenting advice â€” but can we measure an influence on parent's language? and do the interventions lead to children paying more attention?)

Digitally-delivered methods could address some logistic barriers to face-to-face delivery methods. 
Bretenstein reviewed 11 studies on them and showed good promise for the efficacy of interventions using digitally-delivered methods. 
However, the parent and child outcomes assessed in the review (e.g.infant positive behaviors, satisfaction, emotional symptoms etc.) did not address the nature or quality of parent-infant interactions at a detailed level,
like if the interventions lead to children paying more attention, or vocabulary changes in parents' language usages. 
Thus, we want to conduct this experiment to explore if and how digital scaffolding of activities affect the social and linguistic characteristics of parent-child ineractions.

The quality of parent-child interactions can be measured by both the social engagement of parents (e.g., joint attention to objects in the environment) and the quality of language (e.g., vocabulary diversity). 
Although digitally-delivered activities are designed to promote learning and cognitive development, it is unclear how they might affect these dimensions of parent-child interactions. 
How does digital scaffolding of activities affect the social and linguistic characteristics of parents' speech to their children?


# Experiment 1

In Experiment 1, we invited parents of 6- to 24-month-old infants visiting the Children's Discovery Museum in San Jose to complete activities from the Kinedu app. 
Parents were randomly assigned to the video group or the control group; parents in the video group watched a video from the Kinedu app (matched to their child's age), and then performed the activity with their child using the props from the video. 
Parents in the control group did not watch a Kinedu video, instead they were given the same props and were told to play with their infants as they would at home. 
We found that compared to the control group, parents who watched a Kinedu video spoke more words overall, but had lower lexical diversity. 
They also made more bids for joint attention with their infants, although these bids did not result in more episodes of joint attention compared to the control group. 
In summary, following digitally-scaffolded activities may cause parents to engage with and speak more to children overall, but speak more repetitively.

## Method

```{r, echo=F}
e1path = "../../parenting_obs_e1/"
load(paste(e1path,"Exp1_cleaned_data.RData",sep='')) # merged dataframe ready for plotting

lmer_data <- d %>%
  filter(!is.na(AA), !is.na(EL), !is.na(RR))%>%
  mutate(condition = factor(condition), 
         MTLD = as.numeric(MTLD),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         video = as.factor(video))
```

### Participants. 
`r nrow(d)` infants aged 6-24 months and their parents participated in a museum in northern California. 
We included infants who were exposed to English at least 50 percent of the time or who were exposed less but whose participating parent reported that they primarily speak English with their child at home.
*INCLUDE FULL DEMOGRAPHIC INFO*

### Materials.
Stimuli included videos from a commercial parenting application, Kinedu Inc. 
The videos were designed to show activities parents could perform with their child to foster cognitive and physical development, and were targeted to the child's age and development. 
In each video, an adult and child perform the activity while a narrator explains the activity and its purpose. 
We selected two videos for each of three age groups in our sample (6-11.9 months, 12-17.9 months, 18-23.94 months). 
More information about the specific videos is available in the Appendix. 
Participants were also given a set of props corresponding to those in the video they watched, so that they could complete the activity. 
The props associated with each video are listed in the Appendix.

Participants were randomly assigned to either the Activity *Video* condition or the No-Video *Control* condition. 
Participants in the Activity Video condition were assigned to one of the two videos available for their child's age group. 
The No-Video Control condition was yoked to the Activity Video condition such that for every participant in the Activity Video condition who saw a particular video and received the associated props, a participant in the No-Video Control condition received the same props but did not watch the corresponding video.
Parents also completed the Parenting Attitudes Questionnaire (PAQ). 
The PAQ measures parents' attitudes about parenting and child development along three dimensions: rules and respect, early learning, and affection and attachment.

## Procedure.
After providing informed consent, parents in the Activity Video condition watched the assigned video on a laptop with headphones.
To ensure that parents could give the video their full attention, the experimenter played with the infant with a set of toys (different from the experimental props used in the study) while the video was being played. 
Immediately following the video, each parent-child dyad was provided with the props to complete the activity they had viewed. 
The toys were placed on a large foam mat, and parents were instructed to sit on the mat with their child and re-create the activity they had viewed for a period of three minutes.
In the No-Video control condition, after consenting parents were told to play with their child as they would at home with the provided props for a period of three minutes. 
They were not given any additional instructions about how to use the props.

In both conditions, two video cameras were used to record the play session from different angles, and parents were fitted with a wireless audio recorder to record their speech to their child. 
After three minutes of play had elapsed, parents were told they could stop playing and cameras and audio were turned off. 
Parents were then asked to complete the PAQ before being debriefed. 

### Joint Attention Coding Procedure.
The video of each session was manually coded for episodes of joint attention using the Datavyu software. 
The video taken at floor level was coded by default, but the other video was referred to if the participants were not visible or if there was a technological error with the first camera. 
For each participant we coded for episodes of coordinated joint attention, episodes of passive joint attention, and parental bids for joint attention. 
We defined parental bids for joint attention as any attempt to initiate joint attention (i.e label, point, or otherwise draw attention to an object) that does not result in passive or coordinated joint attention. 
If more than 3 seconds elapsed between bids, they were coded as separate attempts. 
An episode of joint attention was considered passive if both participants visually focused on an object for a minimum of 3 seconds but the child did not acknowledge the parent. 
If either participant looked away from the object for less than 3 seconds and then returned to the same object it was considered part of the same period of joint attention. 
Episodes joint attention were considered coordinated if  both participants visually focused on an object for a minimum of 3 seconds and at some point in the interaction the child indicated awareness of interaction with some overt behavior toward the parent. 
This could be looks to the parent's face, gestures, vocalizations, or turn-taking. 
If either participant looked away for less than 3 seconds and then returned to the same object, it was coded as part of the same period of joint attention. 
A second coder independently coded a third of the videos (i.e., 20 of the 60 videos, approximately equally distributed across ages) to establish reliability. *REPORT RELIABILITY*

# Results

The data was analyzed according to our preregistration: [link](https://osf.io/2bpdf/).

## Lexical Diversity

We first calculated Type/Token Ratio (TTR) for each transcript. ..

Fig 1 - TTR, maybe also Total Tokens and Total Types (if subfigures fit)
(otherwise a table with mean and SD of tokens, types, and TTR)
However, note that TTR is a measure that is correlated with the length of a text. ... 
MTLD is a better measure of lexical diversity [@McCarthy2010].

```{r, e1-lexdiv-regressions, echo=F, include=F}
# Predicting lexical diversity based on experimental condition, PAQ, demographics. 
maximal_mod <- lmer(MTLD ~ condition + age + gender + parent_ed + (1| video), data = lmer_data)
summary(maximal_mod)

# predict word tokesn
tokens_mod <- lmer(tokens ~ condition*EL + condition*AA + condition*RR + age + gender + parent_ed + (1| video), 
                         data = lmer_data)
summary(tokens_mod)

# predict word types
types_mod <- lmer(types ~ condition*EL + condition*AA + condition*RR  + age + gender + parent_ed + (1| video), 
                         data = lmer_data)
summary(types_mod)
```

```{r e1lex_div, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean lexical diversity scores by condition (left: Type/Token ratio, right: MTLD) in Experiment 1."}
d$Condition = factor(d$condition, levels = c("con", "exp"), labels = c("Control", "Video"))

# all at once, but there are NAs in SD cols ?
e1 <- d %>% group_by(Condition) %>%
  summarise(TTR=mean(TTR), TTRsd=sd(TTR),
            MTLD=mean(MTLD), MTLDsd=sd(MTLD),
            types=mean(types), types.sd=sd(types),
            tokens = mean(tokens), tokens.sd=sd(tokens))

ms_lex <- d %>%
  group_by(Condition) %>%
  multi_boot_standard(col="TTR") # Type/Token Ratio

ttr_means <- d%>%
  group_by(Condition)%>%
  summarise(mean = mean(TTR), sd = sd(TTR))

# report table with ttr_means lex_sds

e1ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("Type/Token Ratio (TTR)") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_lex_mtld <- d %>%
  group_by(Condition) %>%
  multi_boot_standard(col="MTLD") 

mtld_means <- d %>%
  group_by(Condition)%>%
  summarise(mean = mean(MTLD), sd=sd(MTLD))

# report table with mtld_means

e1mtld <- ggplot(ms_lex_mtld, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

multiplot(e1ttr, e1mtld, cols=2)
```

Word tokens and word types

```{r e1token_type, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word types and word tokens by condition in Experiment 1."}
ms_tok <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "tokens") 

e1tokens <- ggplot(ms_tok, aes(x=Condition, y = mean, fill = Condition)) +geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_type <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "types") 

e1types <- ggplot(ms_type, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e1tokens, e1types, cols=2)
```

```{r, e1-effect-size, echo=F}
cohens_d <- diff(ttr_means$mean) / (sqrt(sum(ttr_means$sd^2)) / 2)
```

## Joint Attention


## Discussion

Both the number of tokens and types are higher in the experimental condition, while lexical diversity (Type/Token ratio) is higher in the control condition. 
Parents may be relatively more repetetive in the experimental condition since they are attempting to stick to a specific prescribed task, but they talk more overall.
Demographics and PAQ do not interact with condition, but there is a marginal effect of RR score on lexical diversity (lower diversity for higher RR scores), and marginal effects of parent education on word types and tokens (more types and tokens for higher parent education).


# Experiment 2

In Experiment 2 we attempt to replicate the findings from Experiment 1 with a restricted number of preregistered predictions. 
We will additionally include a second control condition, in which the same activities are described in written form, rather than being demonstrated in video. 
This manipulation will help determine what the contribution of the video demonstration is in producing the observed effects on parent-child interactions.

## Method

```{r, echo=F}
e2path = "../../parenting_obs_e2/"
load(paste(e2path,"Exp2_cleaned_data.RData",sep=''))

```

### Participants. 
`r nrow(d)` infants aged 12-24 months and their parents participated in the same museum as Experiment 1. 
We included infants who were exposed to English at least 75 percent of the time or who were exposed less but whose participating parent reported that they primarily speak English with their child at home. [specific demo info]

### Materials. 
The design of Experiment 2 was similar to that of Experiment 1, except that instead of a No-Video control condition, parents instead watched a video that was generally related to child development research, but did not give any specific instructions about how to interact with infants or children. 
This was to control for the possibility that differences in language output and joint attention in Experiment 1 could be due to simply cuing parents to think about infants' learning and cognitive development. 
The videos presented in the Control Video condition were media clips (available on YouTube) of developmental psychologists explaining their research interleaved with footage of infants or toddlers engaged in developmental research studies. 
Thus, the content of the videos superficially matched those in the Activity Video condition, but did not suggest any particular activities.
The videos were trimmed to approximately match the average video length in the Activity Video condition (2 minutes ??).

### Procedure. 
The procedure for Experiment 2 matched that of Experiment 1, except that parents in the Control Video condition watched a control video before the play session. 
Consistent with the No-Video control condition in Experiment 1, parents in the Control Video condition were told to play with their child as they would at home, and were not given additional instructions.

# Results

## Lexical Diversity

```{r e2lexdiv, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean lexical diversity scores by condition (left: Type/Token ratio, right: MTLD) in Experiment 2."}
ms_lex <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="TTR") 
ttr_mean <- d%>% group_by(Condition)%>%
  summarise(mean=mean(TTR), sd=sd(TTR))

e2ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + ylim(0.0, 0.6) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("TTR") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_lex <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="MTLD") 
mltd_mean <- d %>% group_by(Condition)%>%
  summarise(mean = mean(MTLD), sd=sd(MTLD))

e2mtld <- ggplot(ms_lex, aes(x = Condition, y = mean, fill = Condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e2ttr, e2mtld, cols=2)
```

```{r e2token-type, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word types and word tokens by condition in Experiment 2."}
ms_tok <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "tokens") 

e2tokens <- ggplot(ms_tok, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_typ <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "types") 

e2types <- ggplot(ms_typ, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e2tokens, e2types, cols=2)
```


## Joint Attention


# Discussion


## Footnotes

Indicate footnotes with a number\footnote{Sample of the first
footnote.} in the text. You can also use 
markdown formatting to include footnotes using this syntax [^1].

[^1]: Sample of a markdown footnote.

## Two-column images

You might want to display a wide figure across both columns. To do this, you change the `fig.env` chunk option to `figure*`. To align the image in the center of the page, set `fig.align` option to `center`. To format the width of your caption text, you set the `num.cols.cap` option to `2`.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
