---
title: "Understanding the impact of electronically-delivered parenting advice"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{ 
      {\large\bf George~Kachergis}^1 (\texttt{kachergis@stanford.edu}) \\
      {\large\bf Emily~Hembacher}^2 (\texttt{emily.hembacher@gmail.com}) \\
      {\large\bf Veronica~Cristiano}^2 (\texttt{CRISTIANO @gallaudet.edu}) \\
      {\large\bf Hanwen Vivian~Zhang}^1 (\texttt{vivian3@stanford.edu}) \\
      {\large\bf Michael C.~Frank}^1 (\texttt{mcfrank@stanford.edu}) \\ 
    ^{1}Department of Psychology, Stanford University \\ 
    Stanford, CA 94305 USA \\
    ^{2} Nextdoor, Inc., Burlingame, CA \\
    ^{3} Gallaudet University, Washington, D.C.
    }

abstract: >
    Early parenting practices play an important role in shaping the future 
    outcomes of young children [@Hart1995; @Heckman2006]. 
    In particular, high-quality early interactions and language input appear to 
    facilitate language learning and result in higher levels of school performance. 
    The rise of phone- and tablet-based parenting applications ("apps") holds the promise of delivering 
    low-cost, positive interventions on parenting style to a wide variety of populations. 
    Of special interest are the parents of very young children, who are often difficult to reach in other ways. 
    Yet little is known about the effects of communicating to parents through app-based interventions.
    In a study of one commercial app offering a collection of age-appropriate activity videos, we find 
    that the quality of parent-child interactions increases in some ways as a result of using the app. 
    Specifically, the lexical diversity of parents' child-directed speech increases, and measures of 
    joint attention show...
    
keywords: >
    digital parenting advice; joint attention; lexical diversity; guided play; 
    
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r libraries, include=F}
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(psych)
library(langcog)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)
source("multiplot.R")

select <- dplyr::select # masked by MASS
theme_set(theme_few())
```

# Introduction

Children of any given age show remarkable variability in their levels of language proficiency [@Fenson1994], 

Young children spend a large portion of their waking time at play, variously manipulating objects, exploring their environment, and interacting with caregivers and peers.
Playing with objects allows them to discover hidden object properties and relations, and to build a causal understanding of how objects interact [e.g., @Schulz2007]. 
Meanwhile, play also gives children an opportunity to set and achieve goals (e.g., build a tower) and to practice a wide range of motor skills (e.g., stacking) that will help them navigate the world [@Singer2006].
Social play can help children learn about human relationships, both through imitation of adult behaviors and by experiencing and learning to process emotional events such as failures [@Singer2006].
Of course, young children are rarely playing in isolation: caregivers often provide encouragement and guidance while scaffolding a child's play [@Kaye1970; @Wood1976]. 
The quality of interactions during such guided play has been shown to influence language learning: parents' joint attention to objects that their child was focused on was positively correlated with the child's subsequent vocabulary growth [@Tomasello1986; @Carpenter1998].
Episodes of joint attention during guided play have also been found to contain more age-appropriate advanced forms of play [@Bigelow2004].
More generally, parenting practices early in childhood have been shown to play an important role in shaping the future outcomes of young children [@Hart1995; @Heckman2006]. 
While interventions often have trouble reaching many parents of very young children, the proliferation of mobile devices offers a good avenut for the digital delivery of parenting advice [@Breitenstein2014].
However, the efficacy of digital parenting advice has not been widely proven. 


## Guided Play Scaffolds Learning
Children's early play behaviors are often assisted by more skilled and knowledgeable play partners such as their caregivers and older siblings [@Kaye1970]. 
Under such expert guidance, children are encouraged and motivated to engage in more advanced play, undertaking explorations that push the boundaries of what they would be able to do unaided [@Vygotsky1980].
These tutorial interactions have been shown to be important components of child development [@Wood1976].
Thus, with the knowledge of both play and tutorial interactions, guided play, which consists of both active and enjoyable activities as well as close guidance of adults [@Hirsh2008] has drawn researchers' interest. 
A study of preschoolers showed that guided play scaffolds the environment while still allowing children to maintain a large degree of control, 
and it outperforms direct-instruction approaches in encouraging a variety of positive academic outcomes [@Weisberg2013].
Another study found that guided play could facilitate children's vocabulary and comprehensive language development and subsequent literacy skills [@Massey2013].

## Improving Parenting Practices and Language Use
Thus, including guided play in parenting practices from an early age may boost children's language and educational outcomes. 
A recent home-visit parenting practices intervention targeting children of low socioeconomic status found that parents in the intervention group gained knowledge of language development, and that this effect sustained four months after the intervention [@Suskind2015].
However, although a number of interactive measures increased during the experiment, including the number of word tokens, conversational turns, and child vocalizations, these increases did not sustain after the intervention.
That changes did not sustain could be due to the intervention itself,
or could merely be that the methods of home-visiting is not sustainable enough for parents to easily and constantly get parenting advice.
Thus, new methods of delivering parenting advice should be considered.

## Effectiveness of Digital Delivery
With the widespread use of smartphones and tablets worldwide, digitally-delivered interventions could address many of the logistical barriers that have limited scaling up face-to-face delivery methods.
A review of 11 studies verified that digital delivery is a promising means of effectively distributing interventions [@Breitenstein2014].
However, the parent and child outcomes assessed in the review (e.g.infant positive behaviors, satisfaction, emotional symptoms etc.) did not address the nature or quality of parent-infant interactions at a detailed level,
like if the interventions lead to children paying more attention, or vocabulary changes in parents' language usages. 
Although digitally-delivered ac-tivities are designed to promote learning and cognitive development, it is unclear how they might affect these dimensions of parent-child interactions.
Thus, we want to conduct this experiment to explore if and how digital scaffolding of activities affect the social and linguistic characteristics of parent-child ineractions.
The quality of parent-child interactions can be measured by both the social engagement of parents (e.g., joint attention to objects in the environment)[@Bigelow2004] and the quality of language (e.g., vocabulary diversity) [@Malvern2004]. 



# Experiment 1

In Experiment 1, we invited parents of 6- to 24-month-old infants visiting the Children's Discovery Museum in San Jose to complete activities from the Kinedu app. 
Parents were randomly assigned to the video group or the control group; parents in the video group watched a video from the Kinedu app (matched to their child's age), and then performed the activity with their child using the props from the video. 
Parents in the control group did not watch a Kinedu video, instead they were given the same props and were told to play with their infants as they would at home. 

## Method

```{r, include=F}
e1path = "../../parenting_obs_e1/"
load(paste(e1path,"Exp1_cleaned_data.RData",sep='')) # merged dataframe ready for plotting

lmer_data <- d %>%
  filter(!is.na(AA), !is.na(EL), !is.na(RR))%>%
  mutate(condition = factor(condition), 
         MTLD = as.numeric(MTLD),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         video = as.factor(video))

a <- d$gender == "F"
length(a[a == TRUE])


```

### Participants. 
`r nrow(d)` infants (F = 42, M = 18) aged 6-24 months (20 6-11.9 month-olds, 20 12-17.9 month-olds, and 20 18-24 month-olds) and their parents participated in a museum in northern California. 
We included infants who were exposed to English at least 50 percent of the time (n = 58) or who were exposed less but whose participating parent reported that they primarily speak English with their child at home (n = 2). 
61% of participants (n = 37) had been exposed to two or more languages as indicated by their parent. 
Parents identified their children as White (n = 25), Asian (n = 11), African American/Black (n = 2), Biracial (n = 12), other (n = 5), or declined to state (n = 5). 
Fifteen parents reported that their child was of Hispanic origin. 
Parents tended to be highly-educated, with reports of highest level of education ranging from completed high school (n = 5), some college (n = 6), four-year college (n = 14), some graduate school (n = 1), to completed graduate school (n = 28) or declined to state (n = 6).

### Materials.
Stimuli included videos from the Kinedu (Kinedu Inc.) commercial parenting application. 
The videos were designed to show activities to parents that they could perform with their child in order to foster cognitive and physical development, and were targeted to the child's age and level of development. 
In each video, an adult and child perform the activity while a narrator explains the activity and its purpose. 
We selected two videos for each of three age groups in our sample (6-11.9 months, 12-17.9 months, 18-23.94 months). 
More information about the specific videos is available in the Appendix. 
Participants were also given a set of toys corresponding to those in the video that they watched so that they could complete the activity. 
The toys associated with each video are listed in the Appendix.

Participants were randomly assigned to either the *Video* condition or the *Control* condition. 
Parents participating in the Video condition were assigned to watch one of the two activity videos available for their child's age group, while parents in the Control condition watched no activity video, and were simply asked to play with their child as they normally would.
The Control condition was yoked to the Activity Video condition such that for every participant in the Video condition who saw a particular video and received the associated props, a participant in the Control condition received the same props but did not watch the activity video.
Parents also completed the Early Parenting Attitudes Questionnaire (EPAQ; [@Hembacher2018]). 
The EPAQ measures parents' attitudes about parenting and child development along three dimensions: rules and respect, early learning, and affection and attachment.

### Procedure.
After providing informed consent, parents in the Video condition watched the assigned activity video on a laptop with headphones.
To ensure that parents could give the video their full attention, the experimenter played with the infant with a set of toys (different from the experimental props used in the study) while the video was being played. 
Immediately following the video, each parent-child dyad was provided with the props to complete the activity the parent had viewed. 
The toys were placed on a large foam mat, and parents were instructed to sit on the mat with their child and re-create the activity they had viewed for a period of three minutes.
In the Control condition, after consenting parents were told to play with their child as they would at home with the provided props for a period of three minutes. 
They were not given any additional instructions about how to use the props.

In both conditions, two video cameras were used to record the play session from different angles, and parents were fitted with a wireless microphone (Shurre lavalier microphone) to record their child-directed speech. 
After three minutes of play had elapsed, parents were told they could stop playing and the cameras and microphone were turned off.
Parents were then asked to complete the EPAQ before being debriefed. 

### Joint Attention Coding Procedure.
The video of each session was manually coded for episodes of joint attention (JA) using the Datavyu software [@datavyu]. 
The video taken at floor level was coded by default, but the other video was referred to if the participants were not visible or if there was technical difficulty with the first camera. 
Each session's video was coded for episodes of coordinated JA, episodes of passive JA, and parental bids for JA. 
Parental bids for JA were defined as any attempt to initiate joint attention (i.e labeling, pointing, or otherwise drawing attention to an object) that did not result in passive or coordinated JA. 
If more than 3 seconds elapsed between bids, they were coded as separate attempts. 
An episode of joint attention was considered passive if both participants visually focused on an object for a minimum of 3 seconds but the child did not acknowledge the parent. 
If either participant looked away from the object for less than 3 seconds and then returned to the same object it was considered part of the same period of joint attention. 
A joint attention episode was considered coordinated if both participants visually focused on an object for a minimum of 3 seconds and at some point in the interaction the child indicated awareness of interaction with some overt behavior toward the parent such as looking at their face, gesturing, vocalizing, or turn-taking. 

A second coder independently coded a third of the videos (i.e., 20 of the 60 videos, approximately equally distributed across ages) to establish reliability. 
The two coders had a reliability of ICC = 0.80 with 95% confident interval (CI) = [0.57,0.92] (p < 0.05) for number of parent bids for JA; ICC = 0.20 with 95% CI = [-0.26,0.58] for number of passive JA episodes; ICC = 0.66 with 95% CI = [0.32,0.85] (p < 0.05) for number of coordinated JA episodes; ICC = 0.24 with 95% CI = [-0.21,0.61] for total duration of passive JA episodes, and ICC = 0.62 with 95% CI = [0.27,0.83] (p < 0.05) for total duration of coordinated JA episodes. 

## Results

The transcripts and hand-coded behavioral data was analyzed according to our preregistration[^1].
Below we first describe the lexical diversity results, followed by the joint attention results.

[^1]: Preregistration: [https://osf.io/2bpdf/](https://osf.io/2bpdf/)]

### Lexical Diversity

Parents' child-directed speech during the play sessions was transcribed.
For each transcript, the words were lemmatized using @spacy2, and the word *types* (unique words) and *tokens* (total words) were then tallied and the type-token ratio (TTR) calculated as a measure of lexical diversity. 
Although TTR was our preregistered measure of lexical diversity, TTR is correlated with the length of a text, whereas the measure of textual lexical diversity (MTLD) is not [@McCarthy2010]. 
Thus, we also measure lexical diversity with MTLD, which is calculated as the mean length of sequential word strings in a text that maintain a given TTR value (here, .720).


```{r, e1-lexdiv-regressions, echo=F, include=F}
# Predicting lexical diversity based on experimental condition, PAQ, demographics. 
modTTR <- lmer(TTR ~ condition + age + gender + parent_ed + (1|video), data=lmer_data)
summary(modTTR) # condition -0.123 t(39.9) = 4.25 p<.001

modMTLD <- lmer(MTLD ~ condition + age + gender + parent_ed + (1|video), data=lmer_data)
summary(modMTLD) # condition -11.67 t(43) = 3.08 p=.004 !! singular fit
# Bayesian regression (stan_glmer in rstanarm) shows the same

# predict word tokens
tokens_mod <- lmer(tokens ~ condition*EL + condition*AA + condition*RR + age + gender + parent_ed + (1|video),  data=lmer_data)
summary(tokens_mod) # condition 57.23 t(34.4) = 2.19 p<.05

# predict word types
types_mod <- lmer(types ~ condition*EL + condition*AA + condition*RR  + age + gender + parent_ed + (1|video), data=lmer_data) # !! singular fit
summary(types_mod) # nothing
```

We fit a mixed-effects linear regression predicting TTR as a function of condition, age (scaled and 0-centered), gender, and parent's education level with a random intercept per video using lme4 [@lme4]. 
There was significantly lower TTR in the Video condition (mean: 0.32) than in the Control condition (mean: 0.43, $\beta=-.12$, t(39.9) = 4.25, *p*<.001). 
There were no significant effects of age, gender, or parent's level of education.
A similar mixed-effects linear regression instead predicting MTLD also found significantly lower lexical diversity in the Video condition (mean: 15.7) than in the Control condition (mean: 21.9, $\beta=-11.67$, t(43) = 3.08, *p*<.01), with no other significant effects.
Figure 1 shows the mean of each lexical diversity measure (TTR and MTLD) by condition.

We also conducted similar regressions predicting the number of word tokens and types, finding only a significant effect of condition on the number of word tokens ($\beta=57.23$, t(34.4)=2.19, *p*<.05), with parents using more words in the Video condition (mean: 225, 95% CI: [197,252]) than in the Control condition (mean: 165, 95% CI: [139,193]).

(Table with mean and SD of tokens, types, and TTR)

```{r e1lex_div, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean lexical diversity scores by condition (left: Type/Token ratio, right: MTLD) in Experiment 1. Error bars show bootstrapped 95 percent confidence intervals (CIs)."}
d$Condition = factor(d$condition, levels = c("con", "exp"), labels = c("Control", "Video"))

# all at once, but there are NAs in SD cols ?
e1 <- d %>% group_by(Condition) %>%
  summarise(TTR=mean(TTR), TTRsd=sd(TTR),
            MTLD=mean(MTLD), MTLDsd=sd(MTLD),
            types=mean(types), types.sd=sd(types),
            tokens = mean(tokens), tokens.sd=sd(tokens))

ms_lex <- d %>%
  group_by(Condition) %>%
  multi_boot_standard(col="TTR") # Type/Token Ratio

ttr_means <- d%>%
  group_by(Condition)%>%
  summarise(mean = mean(TTR), sd = sd(TTR))

# report table with ttr_means lex_sds

e1ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("Type/Token Ratio (TTR)") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_lex_mtld <- d %>%
  group_by(Condition) %>%
  multi_boot_standard(col="MTLD") 

mtld_means <- d %>%
  group_by(Condition)%>%
  summarise(mean = mean(MTLD), sd=sd(MTLD))

# report table with mtld_means

e1mtld <- ggplot(ms_lex_mtld, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

multiplot(e1ttr, e1mtld, cols=2)
```

Word tokens and word types

```{r e1token_type, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word types and word tokens by condition in Experiment 1."}
ms_tok <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "tokens") 

e1tokens <- ggplot(ms_tok, aes(x=Condition, y = mean, fill = Condition)) +geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_type <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "types") 

e1types <- ggplot(ms_type, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e1tokens, e1types, cols=2)
```

```{r, e1-effect-size, echo=F}
cohens_d <- diff(ttr_means$mean) / (sqrt(sum(ttr_means$sd^2)) / 2)
```

### Joint Attention

```{r, e1ja-regressions, echo=F, include=F}
load(paste(e1path,"joint_attention/Exp1_joint_attention_data.RData",sep=''))
d$Condition <- factor(d$Condition, levels = c("con","exp"), labels = c("Control","Video"))

lmer_data <- d %>%
  filter(!is.na(AA), !is.na(EL), !is.na(RR))%>%
  mutate(Condition = factor(Condition), 
         bids_tot = as.numeric(bids_tot),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         Video = as.factor(Video))

model_string =  "~ Condition * EL + Condition * AA + Condition * RR  + age + gender + parent_ed + (1| Video)"

# Total number of bids
bids_mod <- lmer(paste("bids_tot", model_string), data = lmer_data)
summary(bids_mod) # condition beta = 3.51, t(40.3) = 2.95 p<.01, gender p=.05 ?

bid_cond <- lmer_data %>% group_by(Condition) %>% 
  summarise(mean = mean(bids), sd = sd(bids)) 
print(bid_cond)

# Episodes of coordinated joint attention.
cja_mod <- lmer(paste("cja", model_string), data = lmer_data)
summary(cja_mod) # NA

# Episodes of passive joint attention.
pja_mod <- lmer(paste("pja", model_string), data = lmer_data)
summary(pja_mod) # marginal RR, beta=-1.07 p=.07, condition*RR beta=1.83 p<.05


# Total duration of passive joint attention.
pja_time_mod <- lmer(paste("pja_length", model_string), data = lmer_data)
summary(pja_time_mod) # NA

# Total duration of coordinated joint attention.
cja_time_mod <- lmer(paste("cja_length", model_string), data = lmer_data)
summary(cja_time_mod) # marginal parent education p=.09
```

We fit a mixed-effects linear regression predicting the number of bids for joint attention (JA) as a function of fixed effects of condition, age (scaled and 0-centered), gender, parent's education level, and the subscales of the EPAQ: Early Learning (EL), Affection and Attachment (AA), and Rules and Respect (RR), along with interactions of condition and EL, AA, and RR. This lme4 model included random intercepts per video. 
There were significantly more bids for JA in the Video condition (mean: 6.24, sd: 2.79) than in the Control condition (mean: 3.56, sd: 2.50, $\beta=3.51$, t(40.3) = 2.95, *p*<.01). 
There were no other significant effects.
Mixed-effects regressions with the same structure were performed predicting the number of episodes of coordinated and passive JA, and the total duration of time spent in coordinated and passive JA.
There were no significant effects on the number or total duration of coordinated JA episodes, nor on the total duration of passive JA episodes. 
For the regression predicting the number of passive JA episodes, the only significant effect was an interaction of condition and RR ($\beta=1.83$, t(41.5) = 2.22, *p*<.05), showing that for parents in the Video condition, those with higher Rules and Respect subscores engaged in more passive JA episodes.
Figure X shows ... by condition.


```{r e1ja-graphs, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of bids and episodes of Joint Attention in Experiment 1."}

ms_bids <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="bids_tot") 

e1bids <- ggplot(ms_bids, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("Total Bids for Joint Attention") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

# total joint attention episodes
ms_tja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "total_ja") 

e1tja <- ggplot(ms_tja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Episodes of Joint Attention") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 
  
multiplot(e1bids, e1tja, cols=2)
```

```{r e1ja-graphs-pass-coord, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Average number of passive and coordinated episodes of JA in Experiment 1."}
ms_pja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "pja") 

e1pja <- ggplot(ms_pja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Episodes of Passive Joint Attention")  +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

#Episodes of coordinated joint attention
ms_cja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "cja") 

e1cja <- ggplot(ms_cja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Episodes of Coordinated Joint Attention")  +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

multiplot(e1pja, e1cja, cols=2)
```

## Discussion

In summary, while parents produced more word types and tokens after viewing the activity video, lexical diversity (Type/Token ratio and MTLD) was higher when parents were just asked to play as they normally would.
This may suggest that parents in the Video condition are being more repetitive in their attempt to stick to the task prescribed in the video.
Demographics and EPAQ do not interact with condition, but there is a marginal effect of RR score on lexical diversity (lower diversity for higher RR scores), and marginal effects of parent education on word types and tokens (more types and tokens for higher parent education).

There was a main effect of condition on total bids for joint attention. 
Parents in the Video condition, after seeing a video demonstrating an activity, made a greater number of bids for joint attention with their child.
There was no effect of condition on the number of episodes of either passive or coordinated joint attention, or the duration of these episodes. 
There was a marginal effect of gender on bids for joint attention, with parents of males producing more bids. 
There was a marginal interaction between RR scores and condition on passive joint attention, such that the experimental condition increased the number of episodes of PJA to a greater extent for people with high RR scores.
While the electronically-delivered parenting advice increased the number of bids for joint attention by parents, it did not significantly effect the number or duration of episodes of joint attention. 
It may be that child variables had a larger relative impact on the attainment of joint attention.


# Experiment 2

Experiment 1 found that parents who watched a Kinedu video spoke more words overall, but had lower lexical diversity compared to parents who played with their children as they normally would at home. 
Parents who watched a Kinedu video also made more bids for joint attention, although these bids did not result in more episodes of joint attention compared to the control group. 
Experiment 2 attempts to replicate these findings from with a restricted number of preregistered predictions ([link](https://osf.io/2bpdf/)). 

## Method

```{r, echo=F}
e2path = "../../parenting_obs_e2/"
load(paste(e2path,"Exp2_cleaned_data.RData",sep=''))

lmer_data <- d %>%
  mutate(condition = factor(condition), 
         MTLD = as.numeric(MTLD),
         TTR = as.numeric(TTR),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         video = as.factor(video))
```

### Participants. 
`r nrow(d)` infants (F = 37, M = 47) aged 12-24 months (42 12-17.9 month-olds, 42 18-24 month-olds) and their parents participated in the same museum as Experiment 1. 
We included infants who were exposed to English at least 75 percent of the time or who were exposed less but whose participating parent reported that they primarily speak English with their child at home. 
Forty nine% of participants (n = 41) had been exposed to two or more languages as indicated by their parent. 
Parents identified their children as White (n = 39), Asian (n = 20), African American/Black (n = 1), Biracial (n = 9), other (n = 7), or declined to state (n = 8). Sixteen parents reported their child was of Hispanic origin. 
Parents tended to be highly- educated, with reports of highest level of education ranging from completed high school (n = 0), some college (n = 5), four-year college (n = 28), some graduate school (n = 2), to completed graduate school (n = 35) or declined to state (n = 14).

### Materials. 

The design of Experiment 2 was similar to that of Experiment 1, except that instead of a No-Video control condition, parents instead watched a video that was generally related to child development research, but did not give any specific instructions about how to interact with infants or children. 
This was to control for the possibility that differences in language output and joint attention in Experiment 1 could be due to simply cuing parents to think about infants' learning and cognitive development. 
The videos presented in the Control Video condition were media clips (available on YouTube) of developmental psychologists explaining their research interleaved with footage of infants or toddlers engaged in developmental research studies. 
Thus, the content of the videos superficially matched those in the Activity Video condition, but did not suggest any particular activities.
The videos were trimmed to approximately match the average video length in the Activity Video condition (close to 90 s).

### Procedure. 
The procedure for Experiment 2 matched that of Experiment 1, except that parents in the Control Video condition watched a control video before the play session. 
Consistent with the No-Video control condition in Experiment 1, parents in the Control Video condition were told to play with their child as they would at home, and were not given additional instructions.
The coding procedure also matched that of Experiment 1. A second coder independently coded a third of the videos (i.e., 26 of the 84 videos, approximately equally distributed across ages) to establish reliability. 
The two coders had a reliability of ICC = 0.80 with 95% confident interval (CI) = [0.60,0.90] (p < 0.05) for number of parent bids for JA; ICC = 0.74 with 95% CI = [0.59,0.87] (p < 0.05) for number of passive JA episodes; ICC = 0.78 with 95% CI = [0.58,0.90] (p < 0.05) for number of coordinated JA episodes; ICC = 0.72 with 95% CI = [0.46,0.86] (p < 0.05) for total duration of passive JA episodes, and ICC = 0.88 with 95% CI = [0.75,0.94] (p < 0.05) for total duration of coordinated JA episodes. 


## Results

Parents' child-directed speech was transcribed and processed according to the same procedure used in Experiment 1.

### Lexical Diversity
```{r, e2-lexdiv-regressions, echo=F, include=F}
# Predicting lexical diversity based on experimental condition. 
modTTR <- lmer(TTR ~ age * condition + (1 | video), data=lmer_data) 
summary(modTTR) # condition beta=-.09  t(8.7) = 3.06 p=.01

modMTLD <- lmer(MTLD ~ age * condition + (1 | video), data=lmer_data)
summary(modMTLD) # NA

# predict word tokens
tokens_mod <- lmer(tokens ~ age * condition + (1 | video), data=lmer_data)
summary(tokens_mod) # NA

# predict word types
types_mod <- lmer(types ~ age * condition + (1 | video), data=lmer_data)
summary(types_mod) # NA
```

We fit a mixed-effects linear regression predicting TTR and MTLD as a function of age (scaled and 0-centered) and condition with an interaction term, and with random intercepts per video using lme4 [@lme4].
There was significantly lower TTR in the Video condition (mean: 0.38) than in the Control condition (mean: 0.47, $\beta=-.09$, t(8.7) = 3.06, *p*=.01).
There was no significant effect of age.
A similar mixed-effects linear regression instead predicting MTLD found no significant effects of age or condition.
Figure X shows the mean of each lexical diversity measure (TTR and MTLD) by condition.
Regressions with the same structure predicting the number of word tokens and types found no significant effects of age or condition.

(Table with mean and SD of tokens, types, TTR, MTLD)

```{r e2lexdiv, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean lexical diversity scores by condition (left: Type/Token ratio, right: MTLD) in Experiment 2."}

d$Condition = factor(d$condition, levels = c("con", "exp"), labels = c("Control", "Video"))

# all at once, but there are NAs in SD cols ?
e2 <- d %>% group_by(Condition) %>%
  summarise(TTR=mean(TTR), TTRsd=sd(TTR),
            MTLD=mean(MTLD), MTLDsd=sd(MTLD),
            types=mean(types), types.sd=sd(types),
            tokens = mean(tokens), tokens.sd=sd(tokens))

ms_lex <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="TTR") 
ttr_mean <- d%>% group_by(Condition)%>%
  summarise(mean=mean(TTR), sd=sd(TTR))

ttr_means <- d%>%
  group_by(Condition)%>%
  summarise(mean = mean(TTR), sd = sd(TTR))

# report table with ttr_means lex_sds

e2ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + ylim(0.0, 0.6) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("TTR") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_lex <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="MTLD") 
mltd_mean <- d %>% group_by(Condition)%>%
  summarise(mean = mean(MTLD), sd=sd(MTLD))

mtld_means <- d %>%
  group_by(Condition)%>%
  summarise(mean = mean(MTLD), sd=sd(MTLD))

e2mtld <- ggplot(ms_lex, aes(x = Condition, y = mean, fill = Condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e2ttr, e2mtld, cols=2)
```



```{r e2token-type, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word types and word tokens by condition in Experiment 2."}
ms_tok <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "tokens") 

e2tokens <- ggplot(ms_tok, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_typ <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "types") 

e2types <- ggplot(ms_typ, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e2tokens, e2types, cols=2)
```
```{r, e2-effect-size, echo=F}
cohens_d <- diff(ttr_means$mean) / (sqrt(sum(ttr_means$sd^2)) / 2)
```

### Joint Attention
```{r, e2ja-regressions, echo=F, include=F}
load(paste(e2path,"joint_attention/Exp2_joint_attention_data.RData",sep=''))
d$Condition <- factor(d$condition, levels = c("con","exp"), labels = c("Control","Video"))
e2ja = d

t.test(subset(e2ja, Condition=="Control")$bids, subset(e2ja, Condition=="Video")$bids)

# Total number of bids
bids_mod <- lmer(bids ~ age * Condition + (1 | video), data = e2ja)
summary(bids_mod) # singular fit, covergence code: 0 - no effects

# Episodes of coordinated joint attention.
cja_mod <- lmer(cja ~ age * condition + (1 | video), data = e2ja)
summary(cja_mod) # marginal condition: t(79) = 1.88 beta=-5.85 p=.06, age*condition beta=4.92 t(79) = 2.35 p=.02
# also singular fit, covergence code: 0

# Episodes of passive joint attention.
pja_mod <- lmer(pja ~ age * condition + (1 | video), data = e2ja)
summary(pja_mod) # age beta=-2.32 t(26.6) = 2.23 p<.05

# Total duration of passive joint attention.
pja_time_mod <- lmer(pja_length ~ age * condition + (1 | video), data = e2ja)
summary(pja_time_mod) # age beta=-15512 t(79) = 2.40 p<.05

# Total duration of coordinated joint attention.
cja_time_mod <- lmer(cja_length ~ age * condition + (1 | video), data = e2ja)
summary(cja_time_mod) # marginal age: beta=31757 t(79) = 1.81 p=.07
```

```{r e2ja-graphs, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of bids and episodes of Joint Attention in Experiment 2."}

ms_bids <- d %>% group_by(Condition) %>%
  multi_boot_standard(col="bids") 

e2bids <- ggplot(ms_bids, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  xlab("Condition") + ylab("Total Bids for Joint Attention") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

# total joint attention episodes
ms_tja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "total_ja") 

e2tja <- ggplot(ms_tja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Total Episodes of Joint Attention") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 
  
multiplot(e2bids, e2tja, cols=2)
```

```{r e2ja-graphs-pass-coord, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Average number of passive and coordinated episodes of JA in Experiment 2."}
ms_pja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "pja") 

e2pja <- ggplot(ms_pja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Episodes of Passive Joint Attention")  +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

#Episodes of coordinated joint attention
ms_cja <- d %>% group_by(Condition) %>%
  multi_boot_standard(col = "cja") 

e2cja <- ggplot(ms_cja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9))+
  xlab("Condition") + ylab("Episodes of Coordinated Joint Attention")  +
  langcog::scale_colour_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

multiplot(e2pja, e2cja, cols=2)
```

There was a marginal effect of condition on total bids for joint attention. Parents in the experimental condition (i.e., those who saw a video demonstrating an activity) made a greater number of bids for joint attention with their child.
There was no effect of condition on the number of episodes of passive or coordinated JA, nor on the duration of these episodes. 
For passive joint attention, there was a main effect of age on both the number and duration of episodes, with older children having fewer episodes of passive JA and episodes of shorter duration.
Moreover, older children had longer duration episodes of coordinated JA.
These results suggest that as children age, they become more socially engaged in interactions with their caregivers.

# Discussion

In both experiments, the number of tokens was higher in the experimental condition, while the number of types and lexical diversity (Type/Token ratio) were higher in the control condition. 
Parents may be relatively more repetetive in the experimental condition since they are attempting to stick to a specific prescribed task, but they talk more overall.


# Acknowledgements

This work was supported by a gift from Kinedu, Inc. 
Thanks to members of the Language and Cognition Lab at Stanford for helpful discussion.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

# Appendix

## Experiment 1

### Video A (6-11.9 months) "Pick it up"

Parents are told to encourage their child to pick up and drop individual objects. They are also encouraged to place toys on a small cloth and show the child that they can drag the cloth towards them to reach the toys. 

Props: cloth, small plastic horse, small plastic sheep, small plastic elephant, small toy car

### Video B (6-11.9 months) “Animal sounds”

### Video C (12-17.9 months)

### Video D (12-17.9 months)

### Video E (18-23.9 months)

### Video F (18-23.9 months)


## Experiment 2

### Video A (12-17.9 months)

### Video B (12-17.9 months)

### Video C (12-17.9 months)

### Video D (18-23.9 months)

### Video E (18-23.9 months)

### Video F (18-23.9 months)

