---
title: "Understanding the impacts of video-guided activities on parent-child interaction"
author-information: "\\author{ \n  {\\large\\bf George~Kachergis}^1 (\\texttt{kachergis@stanford.edu})
  \\\\\n  {\\large\\bf Emily~Hembacher}^2 (\\texttt{emily.hembacher@gmail.com}) \\\\\n
  \ {\\large\\bf Veronica~Cristiano}^2 (\\texttt{CRISTIANO @gallaudet.edu}) \\\\\n
  \ {\\large\\bf Hanwen Vivian~Zhang}^1 (\\texttt{vivian3@stanford.edu}) \\\\\n  {\\large\\bf
  Michael C.~Frank}^1 (\\texttt{mcfrank@stanford.edu}) \\\\ \n^{1}Department of Psychology,
  Stanford University \\\\  Stanford, CA 94305 USA \\\\ ^{2} Nextdoor, Inc., Burlingame,
  CA \\\\ ^{3} Gallaudet University, Washington, D.C. }\n"
bibliography: library.bib
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
document-params: 10pt, letterpaper
final-submission: \cogscifinalcopy
header-includes: \usepackage{float}
keywords: "digital parenting advice; joint attention; lexical diversity; guided play;
  \n"
csl: apa6.csl
abstract: |
  Early parenting practices play an important role in shaping the future  outcomes of young children [@Hart1995; @Heckman2006].  In particular, high-quality early interactions and language input appear to  facilitate language learning and result in higher levels of school performance.  The rise of phone- and tablet-based parenting applications ("apps") holds the promise of delivering  low-cost, positive interventions on parenting style to a wide variety of populations.  Of special interest are the parents of very young children, who are often difficult to reach in other ways.  Yet little is known about the effects of communicating to parents through app-based interventions. In a study of one commercial app offering a collection of age-appropriate activity videos, we find  that the quality of parent-child interactions increases in some ways as a result of using the app.  Specifically, the lexical diversity of parents' child-directed speech increases, and measures of  joint attention show...
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r libraries, include=F}
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(psych)
library(langcog)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)
library(tidyboot)
library(knitr)
source("multiplot.R")

select <- dplyr::select # masked by MASS
theme_set(theme_few())
```

# Introduction

The quantity and quality of early language input has been found to be strongly associated with later language and academic outcomes [@Hart1995; @Marchman2008; @Cartmill2013; @HirshPasek2015]. Thus, because of the potential for large downstream effects [@Heckman2006], there is tremendous interest in interventions that change children's language environment. 
And because parents define a large portion of that environment, especially before the onset of formal schooling, parent behavior is a critical locus for such interventions. 
Many effective parenting interventions require large resource investments and require many hours of in-person contact [@Jamaica2014; @PerryPreschool2004], making implementation at scale a daunting proposition. 
For this reason, many researchers targeting early language are interested in delivering parenting interventions remotely -- through texts, apps, and videos delivered on digital devices. 
But what do parents take away from these short messages about what to do or how to talk with their children?

The content provided by digital parenting interventions runs the gamut from general parenting messages and facts from child development research to specific advice and suggested activities. 
A growing body of evidence suggests that these digital interventions can be effective across a range of cultures, income levels, and children's ages [for a review, see @Breitenstein2014].
For example, in contrast to a face-to-face parent training intervention, a tablet-based version saw significantly higher session completion rates (51% attendance vs. 85% module completion) and comparable or larger effect sizes on parents' and children's (aged 2 to 5 years) behavior [@Breitenstein2016].
Often, however, the theory of change presupposed by such interventions is relatively vague.
Both within and outside the realm of academic interventions, messages to parents of young children often seek to provide knowledge about some aspect of development (e.g., early language), often in tandem with a suggestion regarding activities.
Such messages are assumed to inform parents' choice of behaviors, spurring them to engage in some target activity, which is assumed to be more stimulating than what parents would have done otherwise. 

This theory of change is typically grounded in ideas about guided play and early language stimulation. 
Child-directed speech varies not only in quantity (i.e., the number of total tokens), but also in quality in terms of the diversity of the tokens [@Malvern2004] or the context-appropriateness of the speech [@Cartmill2013], both of which have been linked to children's subsequent language development.
Further, language learning -- especially the acquisition of early vocabulary in the first years -- appears to be supported preferentially by parents and children _jointly attending_ to some object or activity [@Baldwin1991; @Bigelow2004].
Episodes of joint attention are frequent during guided play, when parents set goals and scaffold their child's activities [@Wood1976; @Weisberg2013].
Thus, the current literature supports interventions that encourage parents to provide high-quality language and interaction through something like guided play -- whether via reading books or playing with a shape-sorter at home, or via a conversation about categories in the supermarket.

But is this theory of change correct? That is, does the provision of knowledge and activities lead to higher-quality play? 
Alternatively, this theory could be wrong in a number of ways. 
By focusing parents on a specific activity, parents may over-focus on achieving the superficial goals of the activity. 
This problem might be especially likely with video messages, which could encourage parents to try to mimic a model's specific speech and/or actions.
Attempting to reproduce such surface details of a video-guided activity could in turn result in less high-quality talk, with less responsiveness to their child's play.
Another possibility is that these messages do produce the desired effect, but only for those parents who already have a general orientation towards children's early learning.

Our current experiments were designed to make a direct test of this question: How do parents change their interactions with young children on the basis of short video parenting messages? 
In two experiments, we collected data from parent-child dyads in a local children's museum. 
We showed parents in the experimental group a single short video modeling an interactive toy-based activity along with a scientific justification. 
Parents in the control group received either no video (Experiment 1) or a video of a recent finding in developmental psychology (Experiment 2). 
We then gave the toys from the video to all dyads and videotaped their interactions, coding for language quantity and quality as well as joint attention. 


# Experiment 1

In Experiment 1, we invited parents of 6- to 24-month-old infants visiting the Children's Discovery Museum in San Jose to complete video-guided activities from Kinedu (Kinedu Inc.), a parenting app that delivers digital parenting advice in the form of short videos.
Parents were randomly assigned to the video condition or the control condition; parents in the _video_ condition watched a video from the Kinedu app (matched to their child's age), and then performed the activity with their child using the props from the video. 
Parents in the _control_ condition did not watch a Kinedu video, but were given a set of the same age-appropriate props and asked to play with their infants as they normally would at home. 

## Method

```{r, include=F}
e1path = "../../parenting_obs_e1/"
load(paste(e1path,"Exp1_cleaned_data.RData",sep='')) # merged dataframe ready for plotting

lmer_data <- d %>%
  #filter(!is.na(AA), !is.na(EL), !is.na(RR))%>%
  mutate(condition = factor(condition), 
         MTLD = as.numeric(MTLD),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         video = as.factor(video))

e1_gender = table(d$gender)
#table(cut_interval(d$age, n=2, breaks=c(.5,1.5,2.1), labels=F))
#table(cut_number(d$age, n=3, breaks=c(.5,1.5,2.1)))
e1_parent_ed = table(d$parent_ed)
```

### Participants. 
`r nrow(d)` infants (F = `r e1_gender['F']`, M = `r e1_gender['M']`) aged 6-24 months (20 6-11.9 month-olds, 20 12-17.9 month-olds, and 20 18-24 month-olds) and their parents participated in a museum in northern California. 
We included infants who were exposed to English at least 50 percent of the time (n = 58) or who were exposed less but whose participating parent reported that they primarily speak English with their child at home (n = 2). 
62% of participants (n = 37) had been exposed to two or more languages, as indicated by their parent. 
Parents identified their children as White (n = 25), Asian (n = 11), African American/Black (n = 2), Biracial (n = 12), other (n = 5), or declined to state (n = 5). 
Fifteen parents reported that their child was of Hispanic origin. 
Parents tended to be highly-educated, with reports of highest level of education ranging from completed high school (n = `r e1_parent_ed[1]`), some college (n = `r e1_parent_ed[2]`), four-year college (n = `r e1_parent_ed[3]`), some graduate school (n = `r e1_parent_ed[4]`), to completed graduate school (n = `r e1_parent_ed[5]`).

### Materials.
Stimuli included videos from the Kinedu commercial parenting application. 
The videos were designed to show activities to parents that they could perform with their child in order to foster cognitive and physical development, and were targeted to the child's age and level of development. 
In each video, an adult and child perform the activity (e.g., sorting toys according to size) while a narrator explains the activity and its purpose. 
We selected two videos for each of three age groups in our sample (6-11.9 months, 12-17.9 months, 18-23.94 months). 
Participants were also given a set of toys corresponding to those in the video that they watched so that they could complete the activity.[^1]

[^1]: Details of the specific videos used and the toys associated with each video are in the Appendix. 

Participants were randomly assigned to either the *Video* condition or the *Control* condition. 
Parents participating in the Video condition were assigned to watch one of the two activity videos available for their child's age group, while parents in the Control condition watched no activity video, and were simply asked to play with their child as they normally would.
The Control condition was yoked to the Video condition such that for every participant in the Video condition who saw a particular video and received the associated props, a participant in the Control condition received the same props but did not watch the activity video.
Parents also completed the Early Parenting Attitudes Questionnaire [EPAQ; @Hembacher2018]. 
The EPAQ measures parents' attitudes about parenting and child development along three dimensions: rules and respect, early learning, and affection and attachment.

### Procedure.
After providing informed consent, parents in the Video condition watched the assigned activity video on a laptop with headphones.
To ensure that parents could give the video their full attention, the experimenter played with the infant with a set of toys (different from the experimental props used in the study) while the video was being played. 
Immediately following the video, each parent-child dyad was provided with the props to complete the video-guided activity that the parent had viewed. 
The toys were placed on a large foam play mat, and parents were instructed to sit on the mat with their child and re-create the activity they had viewed for a period of three minutes.
In the Control condition, after informed consent parents were told to play with their child as they would at home with the provided props for a period of three minutes. 
They were not given any additional instructions about how to use the props.

In both conditions, two video cameras were used to record the play session from different angles, and parents were fitted with a wireless Shurre lavalier microphone to record their child-directed speech. 
After three minutes of play had elapsed, parents were told they could stop playing and the cameras and microphone were turned off.
Parents were then asked to complete the EPAQ before being debriefed. 

### Joint Attention Coding Procedure.
The video of each session was manually coded for episodes of joint attention (JA) using the Datavyu software [@datavyu]. 
The video taken at floor level was coded by default, but the other video was referred to if the participants were not visible or if there was technical difficulty with the first camera. 
Each session's video was coded for episodes of coordinated JA, episodes of passive JA, and parental bids for JA. 
Parental bids for JA were defined as any attempt to initiate joint attention (i.e labeling, pointing, or otherwise drawing attention to an object) that did not result in passive or coordinated JA. 
If more than 3 seconds elapsed between bids, they were coded as separate attempts. 
An episode of joint attention was considered _passive_ if both participants visually focused on an object for 3 or more seconds but the child did not acknowledge the parent. 
If either participant looked away from the object for less than 3 seconds and then returned to the same object it was considered part of the same episode of joint attention. 
A joint attention episode was considered _coordinated_ if both participants visually focused on an object for 3 or more seconds and at some point in the interaction the child indicated awareness of interaction with some overt behavior toward the parent such as looking at their face, gesturing, vocalizing, or turn-taking. 
Full details of our guidelines for coding joint attention are available [here](https://docs.google.com/document/d/1cZrT_Gjt6p0om19lXO-XcFnT09pb0giyhRQ-Pm1yoBU/edit?usp=sharing).

A second coder independently coded a third of the videos (i.e., 20 of the 60 videos, approximately equally distributed across ages) to establish reliability. 
The two coders had a reliability of ICC = 0.80 with 95% confident interval (CI) = [0.57,0.92] for number of parent bids for JA; ICC = 0.20 with 95% CI = [-0.26,0.58] for number of passive JA episodes; ICC = 0.66 with 95% CI = [0.32,0.85] for number of coordinated JA episodes; ICC = 0.24 with 95% CI = [-0.21,0.61] for total duration of passive JA episodes, and ICC = 0.62 with 95% CI = [0.27,0.83] for total duration of coordinated JA episodes. 

## Results

Parents' child-directed speech during the play sessions was transcribed.
The transcripts and hand-coded joint attention data were analyzed according to our preregistration[^2], with any deviations or extensions noted.
Below we first report the lexical diversity results, followed by the joint attention results.

[^2]: Preregistration: [https://osf.io/2bpdf/](https://osf.io/2bpdf/)]

### Lexical Diversity

For each transcript, the words were lemmatized using ``spacy2`` [@spacy2], and the word *types* (unique words) and *tokens* (total words) were then tallied and the type-token ratio (TTR) calculated as a measure of lexical diversity. 
Although TTR was our preregistered measure of lexical diversity as it has commonly been used, it has been noted that TTR is correlated with the length of a text, which has led to the development of new measures such as the measure of textual lexical diversity [MTLD; @McCarthy2010]. 
Thus, we also measure lexical diversity with MTLD, which is calculated as the mean length of sequential word strings in a text that maintain a given TTR value (here we use the value proposed by @McCarthy2010: 0.720).


```{r, e1-lexdiv-regressions, echo=F, include=F}
get_lmer_reporting_values <- function(lmer.fit, digits=2) {
  sm <- summary(lmer.fit)
  Vcov <- vcov(lmer.fit, useScale = FALSE)
  beta <- round(fixef(lmer.fit), digits)
  se <- round(sqrt(diag(Vcov)), digits)
  zval <- round(beta / se, digits)
  pvalEst <- round(2 * pnorm(abs(zval), lower.tail = FALSE), 3)
  pval <- round(sm$coefficients[,"Pr(>|t|)"], 3)
  tval <- abs(round(sm$coefficients[,"t value"], digits))
  df <- round(sm$coefficients[,"df"], 1)
  return(cbind(beta, se, zval, tval, pval, pvalEst, df))
}

require("lmerTest")
# Predicting lexical diversity based on experimental condition, PAQ, demographics. 
modTTR <- lmer(TTR ~ condition + age + gender + parent_ed + (1|video), data=lmer_data)
summary(modTTR) # condition:Exp -0.113 t(52.4) = 4.22 p<.001
e1TTR = get_lmer_reporting_values(modTTR)

modMTLD <- lmer(MTLD ~ condition + age + gender + parent_ed + (1|video), data=lmer_data)
summary(modMTLD) # condition -8.73 t(55) = 2.67 p=.001 !! singular fit
e1MTLD = get_lmer_reporting_values(modMTLD)
# Bayesian regression (stan_glmer in rstanarm) shows the same:
require("rstanarm")
bmodMTLD <- stan_glmer(MTLD ~ condition + age + gender + parent_ed + (1|video), data=lmer_data)
summary(bmodMTLD) # condition mean=-8.6 sd=3.2 95% CI = [-14.9,-2.3]


# predict word tokens
tokens_mod <- lmer(tokens ~ condition*EL + condition*AA + condition*RR + age + gender + parent_ed + (1|video),  data=lmer_data) # only 54 parents completed the EPAQ
summary(tokens_mod) # condition 56.02 t(40.4) = 2.30 p<.05
e1tokens = get_lmer_reporting_values(tokens_mod)

# predict word types
types_mod <- lmer(types ~ condition*EL + condition*AA + condition*RR  + age + gender + parent_ed + (1|video), data=lmer_data) # !! singular fit
summary(types_mod) # nothing (hint: conditionexp:AA beta=19.04 p=.11)
e1types = get_lmer_reporting_values(types_mod) 
# verify with Bayesian regression:
bmod_types <- stan_glmer(types ~ condition*EL + condition*AA + condition*RR  + age + gender + parent_ed + (1|video), data=lmer_data)
summary(bmod_types) # nothing

e1_lexdiv <- lmer_data %>% group_by(condition) %>%
  summarise(TTR=mean(TTR), MTLD=mean(MTLD), tokens=mean(tokens)) 
```

We fit a mixed-effects linear regression predicting TTR as a function of condition, age (0-centered), gender, and parent's education level with a random intercept per video using lme4 [@lme4]. 
There was significantly lower TTR in the Video condition (mean: `r round(subset(e1_lexdiv, condition=='exp')$TTR, 2)`) than in the Control condition (mean: `r round(subset(e1_lexdiv, condition=='con')$TTR, 2)`, $\beta=$`r e1TTR["conditionexp","beta"]`, t(52.4) = `r e1TTR["conditionexp","tval"]`, *p*<.001). 
There were no significant effects of age, gender, or parent's level of education.
A similar mixed-effects linear regression instead predicting MTLD also found significantly lower lexical diversity in the Video condition (mean MTLD: `r round(subset(e1_lexdiv, condition=='exp')$MTLD, 2)`) than in the Control condition (mean: `r round(subset(e1_lexdiv, condition=='exp')$TTR, 2)`, $\beta=$`r e1MTLD["conditionexp","beta"]`, t(55) = `r e1MTLD["conditionexp","tval"]`, *p*=.001), with no other significant effects.
Figure \ref{fig:e1lex_div} shows the mean of each lexical diversity measure (TTR and MTLD) by condition.

```{r e1tokens, echo=F, include=F}
d$Condition = factor(d$condition, levels = c("con", "exp"), labels = c("Control", "Video"))

ms_lex_mtld <- d %>% group_by(Condition) %>%
  tidyboot_mean(MTLD) 
ms_lex <- d %>% group_by(Condition) %>%
  tidyboot_mean(TTR) # Type/Token Ratio
ms_tok <- d %>% group_by(Condition) %>%
  tidyboot_mean(tokens) 
ms_type <- d %>% group_by(Condition) %>%
  tidyboot_mean(types)
```

We also conducted similar regressions predicting the number of word tokens and types, finding only a significant effect of condition on the number of word tokens ($\beta= `r e1tokens["conditionexp","beta"]`$, t(40.4)=`r e1tokens["conditionexp","tval"]`, *p*<.05), with parents using more words in the Video condition (mean: `r round(subset(e1_lexdiv, condition=='exp')$tokens, 0)`, bootstrapped 95% confidence intervals (CI): [`r round(subset(ms_tok, Condition=="Video")$ci_lower, 0)`,`r round(subset(ms_tok, Condition=="Video")$ci_upper, 0)`]) than in the Control condition (mean: `r round(subset(e1_lexdiv, condition=='con')$tokens, 0)`, bootstrapped 95% CI: [`r round(subset(ms_tok, Condition=="Control")$ci_lower, 0)`,`r round(subset(ms_tok, Condition=="Control")$ci_upper, 0)`]).
The means of the lexical diversity measures are reported in Table \ref{e1tab}.


```{r e1tab, echo=FALSE}
e1 <- d %>% group_by(Condition) %>%
  summarise("Mean TTR"=mean(TTR), TTRsd=sd(TTR),
            "Mean MTLD"=mean(MTLD), MTLDsd=sd(MTLD),
            "Mean types"=mean(types), types.sd=sd(types),
            "Mean tokens"= mean(tokens), tokens.sd=sd(tokens))
names(e1) = c("Condition","TTR (M)", "(sd)", "MTLD (M)", "(sd)", "Types (M)", "(sd)", "Tokens (M)", "(sd)")
kable(e1, digits=2, caption="\\label{e1tab} Lexical diversity measures in Experiment 1.")
```

```{r fig:e1lex_div, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e1lex_div} Mean lexical diversity scores by condition (left: Type/Token ratio, right: MTLD) in Experiment 1. Both measures of lexical diversity were significantly lower after watching an activity video. Error bars show bootstrapped 95\\% confidence intervals (CIs), and gray dots indicate values for each participant."}

e1ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .7)) +
  geom_point(data=d, aes(x=Condition, y=TTR), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Type/Token Ratio (TTR)") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 


e1mtld <- ggplot(ms_lex_mtld, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=MTLD), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

multiplot(e1ttr, e1mtld, cols=2)
```

Word tokens and word types

```{r e1token_type, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word tokens (left) and word types (right) by condition in Experiment 1. Parents used significantly more word tokens after watching an activity video. Error bars show bootstrapped 95\\% CIs."}

e1tokens <- ggplot(ms_tok, aes(x=Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=tokens), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

e1types <- ggplot(ms_type, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=types), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e1tokens, e1types, cols=2)
```

```{r, e1-effect-size, echo=F, include=F}
cohens_d <- function(dat) {
  return( diff(dat$mean) / (sqrt(sum(dat$sd^2)) / 2) )
}

ttr_means <- d %>% group_by(Condition) %>%
  summarise(mean = mean(TTR), sd = sd(TTR))
cohens_d(ttr_means) # -1.68 - should we report this?
```

### Joint Attention

```{r, e1ja-regressions, echo=F, include=F}
load(paste(e1path,"joint_attention/Exp1_joint_attention_data.RData",sep=''))
d$Condition <- factor(d$Condition, levels = c("con","exp"), labels = c("Control","Video"))

lmer_data <- d %>%
  filter(!is.na(AA), !is.na(EL), !is.na(RR)) %>%
  mutate(Condition = factor(Condition), 
         bids_tot = as.numeric(bids_tot),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         Video = as.factor(Video))

model_string =  "~ Condition * EL + Condition * AA + Condition * RR  + age + gender + parent_ed + (1| Video)"

# Total number of bids
bids_mod <- lmer(paste("bids_tot", model_string), data = lmer_data)
summary(bids_mod) # condition beta = 3.51, t(40.3) = 2.95 p<.01, gender p=.05 ?
e1bids = get_lmer_reporting_values(bids_mod)

e1bids_M <- lmer_data %>% group_by(Condition) %>% 
  summarise(mean = mean(bids), sd = sd(bids)) 

# Episodes of coordinated joint attention.
cja_mod <- lmer(paste("cja", model_string), data = lmer_data)
summary(cja_mod) # NA

# Episodes of passive joint attention.
pja_mod <- lmer(paste("pja", model_string), data = lmer_data)
summary(pja_mod) # marginal RR, beta=-1.07 p=.07, condition*RR beta=1.83 p<.05 t(41.5)=2.22
e1pja = get_lmer_reporting_values(pja_mod)

# Total duration of passive joint attention.
pja_time_mod <- lmer(paste("pja_length", model_string), data = lmer_data)
summary(pja_time_mod) # NA

# Total duration of coordinated joint attention.
cja_time_mod <- lmer(paste("cja_length", model_string), data = lmer_data)
summary(cja_time_mod) # marginal parent education p=.09 - SINGULAR (do stan_glmer)
```

We fit a mixed-effects linear regression predicting the number of bids for joint attention (JA) as a function of fixed effects of condition, age (scaled and 0-centered), gender, parent's education level, and the subscales of the EPAQ: Early Learning (EL), Affection and Attachment (AA), and Rules and Respect (RR), along with interactions of condition and EL, AA, and RR. 
This lme4 model included random intercepts per video. 
There were significantly more bids for JA in the Video condition (mean: `r round(subset(e1bids_M, Condition=="Video")$mean,2)`, sd: `r round(subset(e1bids_M, Condition=="Video")$sd,2)`) than in the Control condition (mean: `r round(subset(e1bids_M, Condition=="Control")$mean,2)`, sd: `r round(subset(e1bids_M, Condition=="Control")$sd,2)`, $\beta=`r e1bids["ConditionVideo","beta"]`$, t(`r e1bids["ConditionVideo","df"]`) = `r e1bids["ConditionVideo","tval"]`, *p*<.01). 
There were no other significant effects.

Mixed-effects regressions with the same structure were performed predicting the number of episodes of coordinated and passive JA, and the total duration of time spent in coordinated and passive JA.
There were no significant effects on the number or total duration of coordinated JA episodes, nor on the total duration of passive JA episodes. 
For the regression predicting the number of passive JA episodes, the only significant effect was an interaction of condition and RR ($\beta=`r e1pja["ConditionVideo:RR","beta"]`$, t(`r e1pja["ConditionVideo:RR","df"]`) = `r e1pja["ConditionVideo:RR","tval"]`, *p*<.05), showing that for parents in the Video condition, those with higher Rules and Respect subscores engaged in more passive JA episodes.
Figure \ref{fig:e1ja} shows the mean number bids for JA and episodes of JA by condition in Experiment 1.


```{r fig:e1ja, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e1ja} Mean number of bids (left) and episodes (right) of joint attention (JA) by condition in Experiment 1. Parents made significantly more bids for JA after watching an activity video, but this did not result in a greater number of episodes of JA."}

ms_bids <- d %>% group_by(Condition) %>%
  tidyboot_mean(bids_tot) 

e1bids <- ggplot(ms_bids, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=bids_tot), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Mean Bids for Joint Attention") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

# total joint attention episodes
ms_tja <- d %>% group_by(Condition) %>%
  tidyboot_mean(total_ja) 

e1tja <- ggplot(ms_tja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=total_ja), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Mean Episodes of Joint Attention") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 
  
multiplot(e1bids, e1tja, cols=2)
```

```{r fig:e1ja-pass-coord, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e1ja-pass-coord} Mean number of passive (left) and coordinated episodes (right) of JA by condition in Experiment 1."}
ms_pja <- d %>% group_by(Condition) %>%
  tidyboot_mean(pja) 

e1pja <- ggplot(ms_pja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=pja), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Episodes of Passive Joint Attention") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

#Episodes of coordinated joint attention
ms_cja <- d %>% group_by(Condition) %>%
  tidyboot_mean(cja) 

e1cja <- ggplot(ms_cja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=cja), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Episodes of Coordinated Joint Attention")  +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

multiplot(e1pja, e1cja, cols=2)
```

## Discussion

In summary, while parents produced more word types and tokens after viewing the activity video, lexical diversity (both TTR and MTLD) was higher when parents were just asked to play as they normally would.
It may be that parents in the Video condition, in their attempt to stick to the prescribed task, end up repeating themselves more.
Demographics and EPAQ do not interact with condition, although there was a marginal effect of RR score on lexical diversity (lower diversity for higher RR scores), and marginal effects of parent education on word types and tokens (more types and tokens for higher parent education).

Compared to parents in the Control condition, parents who watched an activity video made significantly more bids for JA with their child, although this did not result in a greater number of successful episodes of JA than dyads in the Control condition.
No differences in the duration or number of episodes of passive or coordinated JA between conditions were found. 

There was a marginal effect of gender on bids for JA, with parents of males producing more bids. 
There was an interaction between RR scores and condition on passive JA, such that Video condition increased the number of episodes of passive JA to a greater extent for people with high RR scores.
While the electronically-delivered parenting advice increased the number of bids for JA by parents, it did not significantly affect the number or duration of episodes of JA. 
It may be that children had a larger relative impact on the attainment of joint attention.


# Experiment 2

Experiment 1 found that parents who watched a Kinedu video spoke more words overall, but had lower lexical diversity compared to parents who played with their children as they normally would at home. 
Parents who watched a Kinedu video also made more bids for joint attention, although these bids did not result in more episodes of joint attention compared to the control group. 
Experiment 2 attempts to replicate these findings from with a restricted number of preregistered predictions.[^3]

[^3]: Preregistration: [https://osf.io/2bpdf/](https://osf.io/2bpdf/). 

## Method

```{r, echo=F}
e2path = "../../parenting_obs_e2/"
load(paste(e2path,"Exp2_cleaned_data.RData",sep=''))

lmer_data <- d %>%
  mutate(condition = factor(condition), 
         MTLD = as.numeric(MTLD),
         TTR = as.numeric(TTR),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         video = as.factor(video))

e2_gender = table(d$gender)
e2_ethnicity = table(d$ethnicity)
e2_parent_ed = table(d$parent_ed)
e2_12to18 = nrow(subset(d, age<1.5))
e2_18to24 = nrow(subset(d, age>=1.5))
```

### Participants. 
`r nrow(d)` infants (F = `r e2_gender['F']`, M = `r e2_gender['M']`) aged 12-24 months (`r e2_12to18` 12-17.9 month-olds, `r e2_18to24` 18-24 month-olds) and their parents participated in the same museum as Experiment 1. 
We included infants who were exposed to English at least 75 percent of the time or who were exposed less but whose participating parent reported that they primarily speak English with their child at home. 
Forty-nine percent of participants (n = 41) had been exposed to two or more languages as indicated by their parent. 
Parents identified their children as White (n = 39), Asian (n = 20), African American/Black (n = 1), Biracial (n = 9), other (n = 7), or declined to state (n = 8). Sixteen parents reported their child was of Hispanic origin. 
Parents tended to be highly-educated, with reports of highest level of education ranging from some college (n = `r e2_parent_ed[3]`), four-year college (n = `r e2_parent_ed[4]`), some graduate school (n = `r e2_parent_ed[5]`), to completed graduate school (n = `r e2_parent_ed[6]`) or declined to state (n = 13).

### Materials. 

The design of Experiment 2 was similar to that of Experiment 1, except that instead of No Video control condition, parents instead watched a video that was generally related to child development research, but did not give any specific instructions about how to interact with infants or children. 
This condition was included to control for the possibility that differences in language output and joint attention in Experiment 1 could be due to simply cueing parents to think about infants' learning and cognitive development. 
The videos presented in the Control Video condition were media clips (available on YouTube) of developmental psychologists explaining their research interleaved with footage of infants or toddlers engaged in developmental research studies. 
Thus, the content of the videos superficially matched those in the Activity Video condition, but did not suggest any particular activities.
The videos were trimmed to approximately match the average video length in the Activity Video condition (close to 90 s).
Details of the Kinedu videos used in the Activity Video conditions are in the Appendix.

### Procedure. 
The procedure for Experiment 2 matched that of Experiment 1, except that parents in the Control Video condition watched a control video before the play session. 
Consistent with the No-Video control condition in Experiment 1, parents in the Control Video condition were told to play with their child as they would at home, and were not given additional instructions.
The coding procedure also matched that of Experiment 1. 
A second coder independently coded a third of the videos (i.e., 26 of the 84 videos, approximately equally distributed across ages) to establish reliability. 
The two coders had a reliability of ICC = 0.80 with 95% confidence interval (CI) = [0.60,0.90] for number of parent bids for JA; ICC = 0.74 with 95% CI = [0.59,0.87] for number of passive JA episodes; ICC = 0.78 with 95% CI = [0.58,0.90] for number of coordinated JA episodes; ICC = 0.72 with 95% CI = [0.46,0.86] for total duration of passive JA episodes, and ICC = 0.88 with 95% CI = [0.75,0.94] for total duration of coordinated JA episodes. 


## Results

Parents' child-directed speech was transcribed and processed, and bids and episodes of joint attention were coded according to the same procedure used in Experiment 1.
We first report reregistered regressions predicting TTR and number of tokens, as well as an exploratory regression predicting MTLD.
We then turn to preregistered regressions of parental bids for joint attention and the total number of JA episodes.
As noted in the preregistration, we adopt an alpha level of .005 for statistical significance and will report alphas between .05 and .005 as suggestive.

### Lexical Diversity
```{r, e2-lexdiv-regressions, echo=F, include=F}
# preregistered analyses:
# The number of parent bids for joint attention, the number of episodes of joint attention, the number of word tokens produced by parents, and the lexical diversity of parent language output (word types/word tokens). 
# 1) bids, 2) total JA eps, 3) # tokens 4) TTR -- alpha level = .005
# Mixed-effects linear regressions predicting the dependent variables with condition (video scaffolding vs. control) and age in months as fixed effects and participant and specific video as random effects. 
# DV ~ age * condition + (1 | participant) + (1 | video)
# Lab standard operating procedures will be used for random effects pruning in case of non-convergence.
# We will interpret condition main effects as well as age * condition interactions (positive or negative) as evidence for behavior changes caused by video scaffolding. 
# Because of the larger number of coefficients of interest (4 models x 2 coefficients), we will adopt an alpha level of .005 for statistical significance and will report alpha between .05 and .005 as suggestive.
# “secondary analyses"
# We will analyze the proportion of coordinated vs. passive joint attention separately using the same model specification.

# Notes: 
# - including (1|sid) never works: "Error: number of levels of each grouping factor must be < number of observations", so we back off to (1|video)
# Predicting lexical diversity based on experimental condition. 
modTTR <- lmer(TTR ~ age * condition + (1 | video), data=lmer_data) 
summary(modTTR) # condition beta=-.09  t(8.6) = 3.33 p=.009 (suggestive)
e2TTR <- get_lmer_reporting_values(modTTR) 


# predict word tokens
tokens_mod <- lmer(tokens ~ age * condition + (1 | video), data=lmer_data)
summary(tokens_mod) # NA

modMTLD <- lmer(MTLD ~ age * condition + (1 | video), data=lmer_data)
summary(modMTLD) # NA

e2_lexdiv <- lmer_data %>% group_by(condition) %>%
  summarise(TTR=mean(TTR), MTLD=mean(MTLD), tokens=mean(tokens)) 
# predict word types (NOT A PREREGISTERED REGRESSION)
#types_mod <- lmer(types ~ age * condition + (1 | video), data=lmer_data)
#summary(types_mod) # NA
```

We fit a mixed-effects linear regression predicting TTR as a function of age (0-centered) and condition with an interaction term, and with random intercepts per video using lme4 [@lme4].
There was suggestively lower TTR in the Video condition (mean: `r round(e2_lexdiv[2,]$TTR, 2)`) than in the Control condition (mean: `r round(e2_lexdiv[1,]$TTR, 2)`, $\beta=`r e2TTR["conditionexp","beta"]`$, t(`r e2TTR["conditionexp","df"]`) = `r e2TTR["conditionexp","tval"]`, *p*=`r e2TTR["conditionexp","pval"]`). 
There was no significant effect of age, nor a significant interaction.
The preregistered regression predicting the number of tokens used by parents revealed no significant effects. 
An exploratory mixed-effects linear regression predicting MTLD found no significant effects of age or condition.
Figure \ref{fig:e2lexdiv} shows the mean of each lexical diversity measure (TTR and MTLD) by condition.
Regressions with the same structure predicting the number of words tokens found no significant effects of age or condition.
The means of the lexical measures are shown in Table \ref{e2tab}.


```{r e2tab, echo=F}
d$Condition = factor(d$condition, levels = c("con", "exp"), labels = c("Control", "Video"))
e2 <- d %>% group_by(Condition) %>%
  summarise("Mean TTR"=mean(TTR), TTRsd=sd(TTR),
            "Mean MTLD"=mean(MTLD), MTLDsd=sd(MTLD),
            "Mean types"=mean(types), types.sd=sd(types),
            "Mean tokens"= mean(tokens), tokens.sd=sd(tokens))
names(e2) = c("Condition","TTR (M)", "(sd)", "MTLD (M)", "(sd)", "Types (M)", "(sd)", "Tokens (M)", "(sd)")
kable(e2, digits=2, caption="\\label{e2tab} Lexical diversity measures in Experiment 2.")
```

```{r fig:e2lexdiv, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=5.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e2lexdiv} Mean lexical diversity scores by condition (left: Type/Token ratio, middle: MTLD, right: word tokens) in Experiment 2."}

ms_lex <- d %>% group_by(Condition) %>%
  tidyboot_mean(TTR) 

e2ttr <- ggplot(ms_lex, aes(x=Condition, y=mean, fill=Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=TTR), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("TTR") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_lex <- d %>% group_by(Condition) %>%
  tidyboot_mean(MTLD) 

e2mtld <- ggplot(ms_lex, aes(x = Condition, y = mean, fill = Condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=MTLD), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("MTLD") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

ms_tok <- d %>% group_by(Condition) %>%
  tidyboot_mean(tokens) 

e2tokens <- ggplot(ms_tok, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=tokens), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Number of Word Tokens") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

multiplot(e2ttr, e2mtld, e2tokens, cols=3)
```



```{r e2token-type, include=F, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Mean number of word types and word tokens by condition in Experiment 2."}

ms_typ <- d %>% group_by(Condition) %>%
  tidyboot_mean(types) 

e2types <- ggplot(ms_typ, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=types), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Number of Word Types") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  theme(legend.position="none") 

#multiplot(e2tokens, e2types, cols=2)
```

```{r, e2-effect-size, echo=F, include=F}
ttr_means <- d %>% group_by(Condition) %>%
  summarise(mean = mean(TTR), sd = sd(TTR))
cohens_d(ttr_means)
```

### Joint Attention
```{r, e2ja-regressions, echo=F, include=F}
load(paste(e2path,"joint_attention/Exp2_joint_attention_data.RData",sep=''))
summary(d)
# triplicate variables: gender.x/y, ethnicity, english, num_lang, parent_ed, Exclude
d$Condition <- factor(d$condition, levels = c("con","exp"), labels = c("Control","Video"))

e2ja <- d %>% mutate(bids = bids_tot,
                     age = as.numeric(langcog::scale(age, scale=FALSE)),
                     pja_length = pja_length/1000,
                     cja_length = cja_length/1000,
                     total_lja = total_lja/1000)

# Total number of bids
bids_mod <- lmer(bids ~ age * Condition + (1 | video), data = e2ja)
summary(bids_mod) # singular fit, convergence code: 0 condition beta=3.11, t(80) = 3.52 p<.001
e2bids <- get_lmer_reporting_values(bids_mod)
bids_bmod <- stan_glmer(bids ~ age * Condition + (1|video), data=e2ja)
summary(bids_bmod) # significant effect of condition! mean=3.1, 95%CI = [1.1, 5.0]

tja_mod <- lmer(total_ja ~ age * Condition + (1 | video), data = e2ja)
e2tja <- get_lmer_reporting_values(tja_mod)
summary(tja_mod) # singular fit, convergence code: 0
#                    Estimate Std. Error      df t value  Pr(>|t|) 
# (Intercept)          7.2912     0.3898 80.0000  18.704  < 2e-16 ***
# age                 -5.2687     1.5122 80.0000  -3.484 0.000804 ***
# ConditionVideo       1.4893     0.5513 80.0000   2.701 0.008428 ** 
# age:ConditionVideo   5.9189     2.2721 80.0000   2.605 0.010950 *  

tja_bmod <- stan_glmer(total_ja ~ age * Condition + (1|video), data=e2ja)
summary(tja_bmod) # total episodes of joint attention -- age, age*condition, condition
#                                        mean    sd     2.5%   25%    50%    75%    97.5%
# (Intercept)                             7.3    0.4    6.4    7.0    7.3    7.6    8.2 
# age                                    -5.0    1.7   -8.2   -6.1   -5.0   -3.9   -1.6 
# ConditionVideo                          1.5    0.6    0.3    1.1    1.5    1.9    2.8 
# age:ConditionVideo                      5.6    2.5    0.7    3.9    5.7    7.4   10.5 

e2_bids <- e2ja %>% group_by(Condition) %>%
  tidyboot_mean(bids)
e2_tja <- e2ja %>% group_by(Condition) %>%
  tidyboot_mean(total_ja) 

```

As preregistered, we fit mixed-effects linear regressions predicting the number of parental bids for joint attention and the total number of episodes of JA as a function of fixed effects of condition, age (0-centered), and their interaction, with random intercepts per video.
Shown in Figure \ref{fig:e2ja} (left panel), parents made significantly more bids for JA after watching the Activity Video (mean: `r round(subset(e2_bids, Condition=="Video")$mean,2)`, bootstrapped 95% CI: `r round(subset(e2_bids, Condition=="Video")$ci_lower,2)`, `r round(subset(e2_bids, Condition=="Video")$ci_upper,2)`; $\beta=`r e2bids["ConditionVideo","beta"]`$, t(`r e2bids["ConditionVideo","df"]`) = `r e2bids["ConditionVideo","tval"]`, *p*=`r e2bids["ConditionVideo","pval"]`)) than after the Control Video (mean: `r round(subset(e2_bids, Condition=="Control")$mean,2)`, 95% CI: `r round(subset(e2_bids, Condition=="Control")$ci_lower,2)`, `r round(subset(e2_bids, Condition=="Control")$ci_upper,2)`, $\beta=`r e2bids["ConditionVideo","beta"]`$, t(`r e2bids["ConditionVideo","df"]`) = `r e2bids["ConditionVideo","tval"]`, *p*<.001). 
There were no other significant effects on parental bids for JA.

In the regression predicting the number of episodes of JA, there was a significant main effect of condition ($\beta=`r e2tja["ConditionVideo","beta"]`$, t(`r e2tja["ConditionVideo","df"]`) = `r e2tja["ConditionVideo","tval"]`, *p*=`r e2tja["ConditionVideo","pval"]`), with more episodes of JA occurring after the Activity Video (mean: `r round(subset(e2_tja, Condition=="Video")$mean,2)`, 95% CI: `r round(subset(e2_tja, Condition=="Video")$ci_lower,2)`, `r round(subset(e2_tja, Condition=="Video")$ci_upper,2)`) than after the Control Video (mean: `r round(subset(e2_tja, Condition=="Control")$mean,2)`, 95% CI: `r round(subset(e2_tja, Condition=="Control")$ci_lower,2)`, `r round(subset(e2_tja, Condition=="Control")$ci_upper,2)`).
There was also a significant main effect of age ($\beta=`r e2tja["age","beta"]`$, t(`r e2tja["age","df"]`) = `r e2tja["age","tval"]`, *p*=`r e2tja["age","pval"]`), showing that the number of episodes of JA decreased with the child's age. 
However, a significant interaction of age and condition ($\beta=`r e2tja["age:ConditionVideo","beta"]`$, t(`r e2tja["age:ConditionVideo","df"]`) = `r e2tja["age:ConditionVideo","tval"]`, *p*=`r e2tja["age:ConditionVideo","pval"]`), shown in the right panel of Figure \ref{fig:e2ja}, demonstrates that older children in the Activity Video condition did not see a decrease in the number of episodes of JA.


```{r fig:e2ja, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=6, fig.height=3.0, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e2ja} Mean number of bids for JA by condition (left) and the number of episodes of JA by age and condition (right) in Experiment 2. After watching an activity video, parents made more bids for JA. Older children in the Activity Video condition showed no decrease in the number of episodes of JA, unlike children in the Control Video condition."}

e2bids <- ggplot(e2_bids, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=e2ja, aes(x=Condition, y=bids), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Bids for Joint Attention") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

# total JA episodes
e2tja <- ggplot(e2_tja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=e2ja, aes(x=Condition, y=total_ja), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Total Episodes of Joint Attention") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  theme(legend.position="none") 

e2tja_age = ggplot(d, aes(x = age, y = total_ja, group=Condition, colour = Condition)) +
  geom_point(alpha=.7) + geom_smooth(method='lm') + 
  xlab("Age (years)") + ylab("Total Episodes of Joint Attention") +
  langcog::scale_colour_solarized() +
  ggthemes::theme_few() 

multiplot(e2bids, e2tja_age, cols=4, layout=matrix(c(1,2,2,2), nrow=1))
```



```{r e2ja-exploratory, echo=F, include=F}
# EXPLORATORY ANALYSES (NOT PREREGISTERED)

# Episodes of coordinated joint attention
cja_mod <- lmer(cja ~ age * Condition + (1 | video), data = e2ja)
summary(cja_mod) #  Condition: t(80) = 2.47 beta=1.37 p=.01; age*Condition beta=5.24 t(80) = 2.19 p=.02
e2cja <- get_lmer_reporting_values(cja_mod)
# also singular fit, convergence code: 0 - Bayesian regression confirms:
cja_bmod <- stan_glmer(cja ~ age * Condition + (1|video), data=e2ja)
summary(cja_bmod) # age n.s., sig effect of condition: mean=1.3 95% CI=[.1,2.6]; age*condition mean=5.1 CI=[.5,9.6]
#                                        mean    sd     2.5%   25%    50%    75%    97.5%
# (Intercept)                             5.3    0.4    4.5    5.0    5.3    5.6    6.2 
# age                                    -2.0    1.4   -4.8   -2.9   -2.0   -1.1    0.9 
# ConditionVideo                          1.3    0.6    0.1    0.9    1.3    1.7    2.6 
# age:ConditionVideo                      5.1    2.3    0.5    3.5    5.1    6.5    9.6 

# Episodes of passive joint attention.
pja_mod <- lmer(pja ~ age * Condition + (1 | video), data = e2ja)
summary(pja_mod) # age beta=-2.88 t(13.4) = 2.53 p=.02
e2pja <- get_lmer_reporting_values(pja_mod)

# Total duration of passive joint attention.
pja_time_mod <- lmer(pja_length ~ age * Condition + (1 | video), data = e2ja)
summary(pja_time_mod) # singular - convergence code: 0, age beta=-18.89 t(80) = 2.72 p=.008
e2pja_time <- get_lmer_reporting_values(pja_time_mod)
pjat_bmod <- stan_glmer(pja_length ~ age * Condition + (1|video), data=e2ja)
summary(pjat_bmod) # age: est: -17.9 95% CI = [-33.1,-2.2]

# Total duration of coordinated joint attention.
cja_time_mod <- lmer(cja_length ~ age * condition + (1 | video), data = e2ja)
summary(cja_time_mod) # singular - convergence code: 0, marginal age: beta=37.35 t(80) = 1.95 p=.05
cjat_bmod <- stan_glmer(cja_length ~ age * Condition + (1|video), data=e2ja)
summary(cjat_bmod) # age: est: 35.3 95% CI = [-6.1,77.4] NOT SIGNIFICANT

e2_cja <- e2ja %>% group_by(Condition) %>%
  tidyboot_mean(cja)
```

### Exploratory Analyses

Four additional exploratory regressions with a similar structure were carried out to predict the number and duration of coordinated and passive JA episodes.
The regression predicting the number of episodes of coordinated JA found a significant main effect of condition ($\beta=`r e2cja["ConditionVideo","beta"]`$, t(`r e2cja["ConditionVideo","df"]`) = `r e2cja["ConditionVideo","tval"]`, *p*=`r e2cja["ConditionVideo","pval"]`), with more episodes of coordinated JA occurring after the Activity Video (mean: `r round(subset(e2_cja, Condition=="Video")$mean,2)`, 95% CI: `r round(subset(e2_cja, Condition=="Video")$ci_lower,2)`, `r round(subset(e2_cja, Condition=="Video")$ci_upper,2)`) than after the Control Video (mean: `r round(subset(e2_cja, Condition=="Control")$mean,2)`, 95% CI: `r round(subset(e2_cja, Condition=="Control")$ci_lower,2)`, `r round(subset(e2_cja, Condition=="Control")$ci_upper,2)`).
There was no significant effect of age, but there was a significant interaction of age and condition ($\beta=`r e2cja["age:ConditionVideo","beta"]`$, t(`r e2cja["age:ConditionVideo","df"]`) = `r e2cja["age:ConditionVideo","tval"]`, *p*=`r e2cja["age:ConditionVideo","pval"]`), shown in Figure \ref{e2ja-coord}, revealing that older children in the Activity Video condition had more episodes of coordinated JA than children in the Control Video condition.
The regression predicting the total duration of coordinated JA episodes revealed no significant effects.

In the regression predicting the number of episodes of passive JA, there was a main effect of age ($\beta=`r e2pja["ConditionVideo","beta"]`$, t(`r e2pja["ConditionVideo","df"]`) = `r e2pja["ConditionVideo","tval"]`, *p*=`r e2pja["ConditionVideo","pval"]`), showing that older children had more episodes of passive JA with their caregiver.
The regression predicting the total duration of passive JA revealed a main effect of age ($\beta=`r e2pja_time["ConditionVideo","beta"]`$, t(`r e2pja_time["ConditionVideo","df"]`) = `r e2pja_time["ConditionVideo","tval"]`, *p*=`r e2pja_time["ConditionVideo","pval"]`), revealing that older children spent more time in passive JA with their caregiver.
Overall, these results show that the older children in our sample engage in more and longer episodes of joint attention with their caregivers, and suggest that the Activity Video strengthened this trend in the number of episodes of coordinated JA.

```{r e2ja-coord, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=4.5, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "\\label{fig:e2ja-coord} The number of episodes of coordinated JA by condition and age in Experiment 2. Older children in the Activity Video condition engaged in more episodes of coordinated JA with their caregiver than dyads in the Control Video condition."}

#Episodes of coordinated joint attention
ms_cja <- d %>% group_by(Condition) %>%
  tidyboot_mean(cja) 

e2cja <- ggplot(ms_cja, aes(x = Condition, y = mean, fill = Condition)) + geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = .9)) +
  geom_point(data=d, aes(x=Condition, y=cja), alpha=.2, position = position_jitterdodge()) +
  xlab("Condition") + ylab("Episodes of Coordinated JA") +
  langcog::scale_fill_solarized() + ggthemes::theme_few() + theme(legend.position="none") 

e2cja_age = ggplot(d, aes(x = age, y = cja, group=Condition, colour = Condition)) +
  geom_point(alpha=.7) + geom_smooth(method='lm') + 
  xlab("Age (years)") + ylab("Episodes of Coordinated JA") +
  langcog::scale_colour_solarized() + ggthemes::theme_few() 

print(e2cja_age)
#multiplot(e2cja, e2tja_age, cols=4, layout=matrix(c(1,2,2,2), nrow=1))
```



# Discussion

In both experiments, the number of tokens was higher in the experimental condition, while the number of types and lexical diversity (Type/Token ratio) were higher in the control condition. 
Parents may be relatively more repetetive in the experimental condition since they are attempting to stick to a specific prescribed task, but they talk more overall.


# Acknowledgements

This work was supported by a gift from Kinedu, Inc. 
Thanks to members of the Language and Cognition Lab at Stanford for helpful discussion.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

# Appendix

## Experiment 1

### Video A (6-11.9 months) "Pick it up"

Parents are told to encourage their child to pick up and drop individual objects. They are also encouraged to place toys on a small cloth and show the child that they can drag the cloth towards them to reach the toys. 

Props: cloth, plastic horse, plastic sheep, plastic elephant, toy car

### Video B (6-11.9 months) “Animal sounds”

Parents are told to call different animals and imitate different sounds the animals make. They are also encourgaed to observe which animal the child prefers.

Props: plastic sheep, plastic horse, plastic frog, plastic cow, bowls

### Video C (12-17.9 months) "Give me the toy"

Parents are told to ask their child to hand over individual toys. They are also encouraged to praise the child after they give them the toys, and repeat the process until the child could follow the verbal instructions.

Props: toy boat, plastic frog, plastic elephant, toy bus

### Video D (12-17.9 months) "Classifying my toys"

Parents are told to place toys of different sizes (big or small) in two hoops. They are also encouraged to ask their child to distinguish between two objects and identify which one is larger.

Props: two yellow and green rings, big car, small car, big horse, small horse

### Video E (18-23.9 months) "My toys"

Parents are told to show the child toys of the same shape but different sizes, to place one of the objects in a basket and to ask the child to take out the object. They are also encouraged to ask their child if the object is bigger or smaller compared to its pair.

Props: two buckets, big car, small car, big horse, small horse

### Video F (18-23.9 months) "The Orchestra"

Parents are told to give their child a musical instrument to play. They are also encouraged to play a song and see if the child follows the rhythm.

Props: maracas, drum, tambourine, clapper

## Experiment 2

### Video A (12-17.9 months) "Give me the toy"

Parents are told to ask their child to hand over individual toys. They are also encouraged to praise the child after they give them the toys, and repeat the process until the child could follow the verbal instructions.

Props: plastic pig, plastic horse, plastic dog, plastic cat, plastic cow

### Video B (12-17.9 months) "Classifying my toys"

Parents are told to place toys of different sizes (big or small) in two hoops. They are also encouraged to ask their child to distinguish between two objects and identify which one is larger.

Props: two yellow and green rings, big car, small car, big horse, small horse

### Video C (12-17.9 months) "Geometric shapes jigzsaw puzzle"

Parents are told to encourage their child to name different shapes on a jigzsaw puzzle. Then they are told to undo the puzzle and invite the child to complete the puzzle. 

Props: A jigzsaw puzzle of geometric shapes

### Video D (18-23.9 months) "My toys"

Parents are told to show the child toys of the same shape but different sizes, to place one of the objects in a basket and to ask the child to take out the object. They are also encouraged to ask their child if the object is bigger or smaller compared to its pair.

Props: two buckets, big car, small car, big horse, small horse

### Video E (18-23.9 months) "The Orchestra"

Parents are told to give their child a musical instrument to play. They are also encouraged to play a song and see if the child follows the rhythm.

Props: maracas, drum, tambourine, clapper

### Video F (18-23.9 months) "My Yellow Toys"

Parents are told to show their child yellow toys and to ask, "What color are they?" They are also told to give the child toys of different colors, to ask them to only play with the yellow ones, and to praise the child after they do so.

Props: blue car, yellow car, yellow block, red block, blue block, green block

